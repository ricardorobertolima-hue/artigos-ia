# ğŸ§  Do Naive RAG ao Agentic RAG: Arquiteturas Modernas para Sistemas de IA em 2026

## Autor
Ricardo Roberto  
Engenheiro de Dados | Engenheiro de IA Generativa | Arquiteto de SoluÃ§Ãµes em IA

---

## ğŸ“Œ IntroduÃ§Ã£o

Retrieval-Augmented Generation (RAG) surgiu como uma soluÃ§Ã£o prÃ¡tica para reduzir alucinaÃ§Ãµes em Large Language Models (LLMs), conectando modelos generativos a fontes externas de conhecimento. Durante anos, o **Naive RAG** foi suficiente para provas de conceito e aplicaÃ§Ãµes simples.

Entretanto, **em 2026, esse modelo estÃ¡ obsoleto para sistemas reais**.

OrganizaÃ§Ãµes exigem hoje:
- PrecisÃ£o semÃ¢ntica
- Autonomia operacional
- Controle e validaÃ§Ã£o das respostas
- Capacidade de lidar com dados inconsistentes e dinÃ¢micos
- IntegraÃ§Ã£o com workflows complexos de negÃ³cio

Este artigo apresenta uma **visÃ£o completa das arquiteturas modernas de RAG**, explicando:
- caracterÃ­sticas
- casos de uso
- vantagens e limitaÃ§Ãµes
- **exemplos prÃ¡ticos em Python**

O foco Ã© engenharia aplicada, nÃ£o teoria abstrata.

---

## 1ï¸âƒ£ Naive RAG â€“ O ponto de partida (e o limite)

### ğŸ“– O que Ã©

O Naive RAG Ã© a forma mais simples de Retrieval-Augmented Generation. Ele combina:
1. Embeddings de documentos
2. Um banco de dados vetorial
3. RecuperaÃ§Ã£o dos *top-k* documentos
4. Envio direto ao LLM

### ğŸ§  Arquitetura

UsuÃ¡rio â†’ Embedding â†’ Vector DB â†’ Top-k â†’ Prompt â†’ LLM


### âœ… Quando usar
- Provas de conceito (PoC)
- Demos educacionais
- ProtÃ³tipos rÃ¡pidos

### âŒ LimitaÃ§Ãµes
- RecuperaÃ§Ã£o superficial
- Contextos irrelevantes
- Nenhuma validaÃ§Ã£o da resposta
- NÃ£o lida bem com ambiguidade ou dados complexos

### ğŸ§ª Exemplo em Python

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

docs = [
    "O mercado livre de energia permite negociaÃ§Ã£o direta entre consumidores e fornecedores.",
    "No ACL, contratos sÃ£o firmados bilateralmente."
]

embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(docs, embeddings)

qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4o-mini"),
    retriever=vectorstore.as_retriever(k=2)
)

print(qa.run("O que Ã© o mercado livre de energia?"))

ğŸ“‰ ConclusÃ£o: funcional, mas insuficiente para produÃ§Ã£o.
2ï¸âƒ£ Modular / Advanced RAG â€“ O novo baseline
ğŸ“– O que Ã©

O Modular RAG evolui o Naive RAG ao introduzir componentes especializados, permitindo controle fino do pipeline.

Principais mÃ³dulos:

    Query Rewriting

    Chunking inteligente

    Filtros semÃ¢nticos

    Reranking de resultados

ğŸ§  Arquitetura

Query
 â†“
Query Rewriter
 â†“
Retriever (k alto)
 â†“
Reranker
 â†“
Context Builder
 â†“
LLM

âœ… Problemas que resolve

    Recall baixo

    Contextos irrelevantes

    Respostas genÃ©ricas

ğŸ§ª Exemplo com Reranker

from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker

reranker = CrossEncoderReranker(
    model_name="cross-encoder/ms-marco-MiniLM-L-6-v2"
)

compression_retriever = ContextualCompressionRetriever(
    base_retriever=vectorstore.as_retriever(k=10),
    base_compressor=reranker
)

docs = compression_retriever.get_relevant_documents(
    "Explique riscos financeiros no mercado livre de energia"
)

ğŸ“Œ Hoje, este Ã© o mÃ­nimo aceitÃ¡vel em sistemas corporativos.
3ï¸âƒ£ GraphRAG â€“ Conhecimento alÃ©m de vetores
ğŸ“– O que Ã©

GraphRAG combina LLMs com Grafos de Conhecimento, permitindo raciocÃ­nio baseado em relaÃ§Ãµes, nÃ£o apenas similaridade semÃ¢ntica.
ğŸ§  Casos de uso

    Energia (contratos, agentes, usinas)

    SaÃºde (paciente â†’ exame â†’ diagnÃ³stico)

    JurÃ­dico (leis â†’ precedentes â†’ decisÃµes)

    Compliance e governanÃ§a

ğŸ§  Arquitetura

Query
 â†“
Entity Linking
 â†“
Subgrafo relevante
 â†“
ContextualizaÃ§Ã£o
 â†“
LLM

ğŸ§ª Exemplo em Python (Neo4j)

from neo4j import GraphDatabase

driver = GraphDatabase.driver(
    "bolt://localhost:7687",
    auth=("neo4j", "senha")
)

def load_context():
    with driver.session() as session:
        result = session.run("""
        MATCH (c:Contrato)-[:ASSOCIADO_A]->(e:Empresa)
        RETURN c.descricao, e.nome
        """)
        return [r.data() for r in result]

context = load_context()

ğŸ“Œ O subgrafo retornado Ã© usado como contexto estruturado para o LLM.
4ï¸âƒ£ CRAG / CAG â€“ RAG com controle de qualidade
ğŸ“– O que Ã©

Corrective RAG (CRAG) introduz verificaÃ§Ã£o automÃ¡tica da resposta, garantindo que o conteÃºdo gerado seja sustentado pelo contexto recuperado.
ğŸ§  Arquitetura

Query â†’ Retriever â†’ LLM
               â†“
           Validator
               â†“
       (Aceita ou Reprocessa)

âœ… Quando usar

    DecisÃ£o financeira

    RelatÃ³rios executivos

    Compliance

    Sistemas crÃ­ticos

ğŸ§ª Exemplo de validaÃ§Ã£o

def validate_answer(answer, context, llm):
    prompt = f"""
    A resposta abaixo Ã© correta com base no contexto?

    Contexto:
    {context}

    Resposta:
    {answer}

    Responda apenas SIM ou NÃƒO.
    """
    return llm.predict(prompt)

if validate_answer(answer, context, llm) == "NÃƒO":
    print("Reexecutando retrieval...")

ğŸ“Œ CRAG reduz erros persistentes e aumenta confiabilidade.
5ï¸âƒ£ Agentic / Adaptive RAG â€“ Autonomia real
ğŸ“– O que Ã©

Agentic RAG representa o estado da arte.
Aqui, agentes decidem:

    quando buscar dados

    onde buscar

    quando parar

    como validar resultados

ğŸ§  Arquitetura

Planner Agent
   â†“
Retriever Agent â†” Critic Agent
   â†“
Executor Agent

ğŸ§ª Exemplo com LangGraph

from langgraph.graph import StateGraph

def retrieve(state):
    state["docs"] = retriever.invoke(state["question"])
    return state

def critic(state):
    state["retry"] = len(state["docs"]) < 3
    return state

graph = StateGraph(dict)
graph.add_node("retrieve", retrieve)
graph.add_node("critic", critic)

graph.set_entry_point("retrieve")
graph.add_edge("retrieve", "critic")

agent = graph.compile()
agent.invoke({"question": "Qual o melhor contrato de energia hoje?"})

ğŸ“Œ Base para copilotos corporativos e automaÃ§Ã£o cognitiva.
6ï¸âƒ£ Multi-Modal / Web-RAG â€“ Dados vivos
ğŸ“– O que Ã©

Multi-Modal RAG integra mÃºltiplas fontes:

    Texto

    PDFs

    Imagens

    Web em tempo real

ğŸ§ª Exemplo de Web-RAG

from langchain.tools import DuckDuckGoSearchRun

search = DuckDuckGoSearchRun()
web_data = search.run("preÃ§o spot energia Brasil hoje")

response = llm.predict(
    f"Use os dados abaixo para responder:\n{web_data}"
)

ğŸ“Œ Essencial para dados dinÃ¢micos e anÃ¡lises de mercado.
ğŸ“Š Comparativo Geral
Arquitetura	Complexidade	Uso Ideal
Naive RAG	Baixa	PoC
Modular RAG	MÃ©dia	ProduÃ§Ã£o
GraphRAG	Alta	Conhecimento complexo
CRAG	MÃ©dia	Alta precisÃ£o
Agentic RAG	Alta	Workflows reais
Multi-Modal RAG	MÃ©dia/Alta	Dados vivos
ğŸ”š ConclusÃ£o

Em 2026, RAG nÃ£o Ã© mais um componente isolado.
Ele faz parte de arquiteturas cognitivas completas, combinando:

    Vetores + Grafos

    RAG + Agentes

    ValidaÃ§Ã£o automÃ¡tica

    Observabilidade

    GovernanÃ§a e controle

ğŸ‘‰ Sistemas que permanecem no Naive RAG sÃ£o frÃ¡geis, imprecisos e nÃ£o escalam.

O futuro pertence a RAG autÃ´nomo, adaptativo e confiÃ¡vel.
